{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by : Soong Cun Yuan\n",
    "SUTD : 1002074\n",
    "Course: Artificial Intelligence 50.021\n",
    "Course Instructor Professor Alexander Binder\n",
    "Transfer Learning\n",
    "Fine Tuning of Neural Networks\n",
    "\n",
    "\"\"\"\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "photo_dir = \"photos_8000/\"\n",
    "import sys\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] ---Data preprocessing [Start]--- \n",
    "data= np.genfromtxt('concepts_2011.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "file = 'trainset_gt_annotations.txt'\n",
    "train_set =[]\n",
    "f = open(file, 'r')\n",
    "no_lines = 0\n",
    "for line in f:\n",
    "    line_split = line.split()\n",
    "    train_set.append(line_split)\n",
    "    no_lines+=1\n",
    "print(no_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of Indoor data: 1894\n",
      "Total Size of Outdoor data: 4173\n"
     ]
    }
   ],
   "source": [
    "# Annotation\n",
    "# index 14 = indoor, index 15 = outdoor\n",
    "outdoor = []\n",
    "indoor = []\n",
    "for i in range(no_lines):\n",
    "    #index zero is y value therefore +1\n",
    "    if train_set[i][14]=='1':\n",
    "        indoor.append(train_set[i])\n",
    "    if train_set[i][15]=='1':\n",
    "        outdoor.append(train_set[i])\n",
    "print(\"Total size of Indoor data: {}\\nTotal Size of Outdoor data: {}\".format(len(indoor),len(outdoor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_splitter(ar):\n",
    "    \"\"\"\n",
    "    [1] Shuffles the data.\n",
    "    [2] Split data into features and target.\n",
    "    [3] Save it as name of file first.\n",
    "    \"\"\"\n",
    "    random.shuffle(ar)\n",
    "    x = []\n",
    "    y = []\n",
    "    for n in range(len(ar)):\n",
    "#         x.append(Image.open(photo_dir+ar[n][0][:-4]+\".jpg\").convert('RGB'))\n",
    "#         x.append(np.load(photo_dir+ar[n][0]+\"_ft.npy\"))\n",
    "        x.append(photo_dir+ar[n][0][:-4]+\".jpg\")\n",
    "\n",
    "        y.append(ar[n][1:])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the xy into features and targets\n",
    "features_i, target_i = xy_splitter(indoor)\n",
    "features_o, target_o = xy_splitter(outdoor)\n",
    "# Split them into train, validation and test accordingly\n",
    "# Split training : validation : test in 0.7:0.15:0.15 ratio \n",
    "\n",
    "# This is done with respect to the proportion of indoor : outdoor\n",
    "itrain_size = int(np.floor((len(indoor))*0.7))\n",
    "ivalidate_size = int(np.floor((len(indoor))*0.15))\n",
    "itest_size =  int(len(indoor) - itrain_size - ivalidate_size)\n",
    "\n",
    "otrain_size = int(np.floor((len(outdoor))*0.7))\n",
    "ovalidate_size = int(np.floor((len(outdoor))*0.15))\n",
    "otest_size =  int(len(outdoor) - otrain_size - ovalidate_size)\n",
    "\n",
    "# This is done independently when splitting to ensure that training, validating and testing, we get an equal portion of indoor/outdoor in the sets.\n",
    "indoor_train_dataset, indoor_validate_dataset ,indoor_test_dataset = torch.utils.data.random_split(indoor, [itrain_size, ivalidate_size, itest_size])\n",
    "outdoor_train_dataset, outdoor_validate_dataset ,outdoor_test_dataset = torch.utils.data.random_split(outdoor, [otrain_size, ovalidate_size, otest_size])\n",
    "\n",
    "# Create the full splitted datasets # Note remember to shuffle\n",
    "train_dataset = indoor_train_dataset + outdoor_train_dataset\n",
    "validate_dataset = indoor_validate_dataset + outdoor_validate_dataset\n",
    "test_dataset = indoor_test_dataset + outdoor_test_dataset\n",
    "\n",
    "# [1] ---Data preprocessing [End]--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] ---Define class the training,validation and test sets [start]---\n",
    "class Dataset(utils.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for transfer learning\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset,transform):\n",
    "        \"\"\" \n",
    "        [1] Input the dataset\n",
    "        \"\"\"\n",
    "        self.dataset = np.array(dataset)\n",
    "        self.feature, self.target = xy_splitter(np.array(self.dataset))\n",
    "        self.len = len(self.dataset)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        # here we load the image \n",
    "        feature = self.feature[index]\n",
    "#         print(feature)\n",
    "        feature = Image.open(feature).convert('RGB')\n",
    "        feature_t = self.transform(feature)\n",
    "        target_t = self.target[index]\n",
    "        # indoor is 1, outdoor is 0.\n",
    "        _, target_t = torch.max(torch.tensor([int(target_t[13]), int(target_t[14])]), 0)\n",
    "        if self.transform == five:\n",
    "                # if using five crop we need multiple the target by five\n",
    "            target_t = torch.stack((target_t,target_t,target_t,target_t,target_t))\n",
    "        data = [feature_t,target_t]\n",
    "        return data\n",
    "# All the transform.\n",
    "# five crop\n",
    "five = transforms.Compose([\n",
    "        transforms.Resize(280),\n",
    "        transforms.FiveCrop(224),\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])(crop) for crop in crops])),\n",
    "        ])\n",
    "# single crop with random resize and flips\n",
    "one = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "# [2] ---Define class for training,validation and test sets [End]---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a deep neural network in three different modes A,B,C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] ---Define Train and Evaluate methods [Start]---\n",
    "\n",
    "def train(model, dataloader,optimizer,criterion,transform_type):\n",
    "    model.train()\n",
    "    no_data = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "    if transform_type ==one:\n",
    "        for n in dataloader:\n",
    "            image = n[0].to(device)\n",
    "            target = n[1].to(device)\n",
    "            target = target.view([-1])\n",
    "            optimizer.zero_grad() # set to zero \n",
    "            results = model(image)\n",
    "            pred = results.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            loss = criterion(results,target)\n",
    "            loss.backward() # Update weights\n",
    "            #optimizer.step updates the value of x using the gradient x.grad\n",
    "            optimizer.step() # x.grad += dloss/dx\n",
    "    if transform_type == five:\n",
    "        for n in dataloader:\n",
    "#               #Let pytorch infer the shape  \n",
    "#             image = n[0].view([-1,n[0].shape[-3],n[0].shape[-2],n[0].shape[-1]])\n",
    "#             image = image.to(device)\n",
    "            image = n[0].to(device)\n",
    "            batchsize, crops, c, h, w = image.size()\n",
    "            image.view(-1, c, h, w)\n",
    "            target = n[1].to(device)\n",
    "            target = target.view([-1])\n",
    "            optimizer.zero_grad()\n",
    "            results = model(image)\n",
    "            pred = results.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            loss = criterion(results,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    accuracy = correct/no_data\n",
    "#     print(\"\\nEpoch:{} \\nTraining Loss is {}\".format(epoch_num,loss))\n",
    "    return loss , accuracy\n",
    "\n",
    "def evaluate(model,dataloader,criterion):\n",
    "    tLoss = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    no_data = len(dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for n in dataloader:\n",
    "            image, target = n[0].to(device) ,n[1].to(device)\n",
    "            results = model(image)\n",
    "            tLoss += criterion(results,target).item()\n",
    "            \n",
    "            pred = results.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = correct / no_data\n",
    "    tLoss = tLoss/no_data\n",
    "#     print(\"Evaluation Loss :{}\\n Accuracy :{}\".format(tLoss,accuracy))\n",
    "    return tLoss, accuracy\n",
    "\n",
    "# [3] ---Define Train and Evaluate methods [End]---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [A]--- Transfer learning once without loading weights and training all layers[Start]---\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# trying out resnet for part A\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "# Model resnet\n",
    "num_ftrs = resnet.fc.in_features\n",
    "# print(num_ftrs)\n",
    "resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetA=resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batchSize = 4\n",
    "optimizer = optim.SGD(resnet.parameters(), lr = 1e-3, momentum=0.9)\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,10)\n",
    "\n",
    "# Create Training Instance and its loader, THIS IS DONE ONCE FOR ALL THREE VERSION OF TRANSFER LEARNING\n",
    "trainInstance = Dataset(train_dataset, one)\n",
    "trainLoader = utils.DataLoader(trainInstance, batchSize,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# Create validation Instance and its loader\n",
    "validInstance = Dataset(validate_dataset,one)\n",
    "validLoader = utils.DataLoader(validInstance, batchSize,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# Create test Instance and its loader\n",
    "testInstance = Dataset(test_dataset,one)\n",
    "testLoader = utils.DataLoader(testInstance, batchSize,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[1 / 30]\n",
      "Validating Now... Epoch[1 / 30]\n",
      "Found a better loss! Epoch: 1 Validation Loss:0.1739527407881975  Validation Accuracy:0.7117711771177118\n",
      "\n",
      "Epoch Summary of Epoch:1\n",
      "Training Loss:0.34490054845809937 train_accuracy:0.6373056994818653\n",
      "Validation Loss:0.1739527407881975  Validation Accuracy:0.7117711771177118\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[2 / 30]\n",
      "Validating Now... Epoch[2 / 30]\n",
      "Found a better loss! Epoch: 2 Validation Loss:0.1463713115296348  Validation Accuracy:0.713971397139714\n",
      "\n",
      "Epoch Summary of Epoch:2\n",
      "Training Loss:0.40138164162635803 train_accuracy:0.6773433820065945\n",
      "Validation Loss:0.1463713115296348  Validation Accuracy:0.713971397139714\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[3 / 30]\n",
      "Validating Now... Epoch[3 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:3\n",
      "Training Loss:0.49784964323043823 train_accuracy:0.6723975506358926\n",
      "Validation Loss:0.19399515745138834  Validation Accuracy:0.6182618261826183\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[4 / 30]\n",
      "Validating Now... Epoch[4 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:4\n",
      "Training Loss:0.06725537776947021 train_accuracy:0.689119170984456\n",
      "Validation Loss:0.14649834295343384  Validation Accuracy:0.7667766776677668\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[5 / 30]\n",
      "Validating Now... Epoch[5 / 30]\n",
      "Found a better loss! Epoch: 5 Validation Loss:0.14015950447786496  Validation Accuracy:0.7304730473047305\n",
      "\n",
      "Epoch Summary of Epoch:5\n",
      "Training Loss:0.6570557355880737 train_accuracy:0.6975977390485163\n",
      "Validation Loss:0.14015950447786496  Validation Accuracy:0.7304730473047305\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[6 / 30]\n",
      "Validating Now... Epoch[6 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:6\n",
      "Training Loss:0.2765803933143616 train_accuracy:0.703485633537447\n",
      "Validation Loss:0.1514155599969973  Validation Accuracy:0.7447744774477447\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[7 / 30]\n",
      "Validating Now... Epoch[7 / 30]\n",
      "Found a better loss! Epoch: 7 Validation Loss:0.12816967935648688  Validation Accuracy:0.757975797579758\n",
      "\n",
      "Epoch Summary of Epoch:7\n",
      "Training Loss:1.2124063968658447 train_accuracy:0.7133772962788507\n",
      "Validation Loss:0.12816967935648688  Validation Accuracy:0.757975797579758\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[8 / 30]\n",
      "Validating Now... Epoch[8 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:8\n",
      "Training Loss:0.5575466156005859 train_accuracy:0.7373999057936882\n",
      "Validation Loss:0.1307847395506498  Validation Accuracy:0.7513751375137514\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[9 / 30]\n",
      "Validating Now... Epoch[9 / 30]\n",
      "Found a better loss! Epoch: 9 Validation Loss:0.12328381993786336  Validation Accuracy:0.7766776677667767\n",
      "\n",
      "Epoch Summary of Epoch:9\n",
      "Training Loss:0.3269159495830536 train_accuracy:0.7404616109279322\n",
      "Validation Loss:0.12328381993786336  Validation Accuracy:0.7766776677667767\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[10 / 30]\n",
      "Validating Now... Epoch[10 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:10\n",
      "Training Loss:0.285888671875 train_accuracy:0.7534149788035799\n",
      "Validation Loss:0.1264549779764103  Validation Accuracy:0.7546754675467546\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[11 / 30]\n",
      "Validating Now... Epoch[11 / 30]\n",
      "Found a better loss! Epoch: 11 Validation Loss:0.1227128881760294  Validation Accuracy:0.7722772277227723\n",
      "\n",
      "Epoch Summary of Epoch:11\n",
      "Training Loss:0.6043201088905334 train_accuracy:0.7637776731040979\n",
      "Validation Loss:0.1227128881760294  Validation Accuracy:0.7722772277227723\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[12 / 30]\n",
      "Validating Now... Epoch[12 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:12\n",
      "Training Loss:1.480852484703064 train_accuracy:0.7072538860103627\n",
      "Validation Loss:0.12672565056152468  Validation Accuracy:0.7524752475247525\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[13 / 30]\n",
      "Validating Now... Epoch[13 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:13\n",
      "Training Loss:1.4771921634674072 train_accuracy:0.7178520960904381\n",
      "Validation Loss:0.13551356249188695  Validation Accuracy:0.7403740374037404\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[14 / 30]\n",
      "Validating Now... Epoch[14 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:14\n",
      "Training Loss:0.15885812044143677 train_accuracy:0.7232689590202543\n",
      "Validation Loss:0.13392617705107  Validation Accuracy:0.7623762376237624\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[15 / 30]\n",
      "Validating Now... Epoch[15 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:15\n",
      "Training Loss:0.6752938032150269 train_accuracy:0.7246820536975978\n",
      "Validation Loss:0.12849941680861515  Validation Accuracy:0.7491749174917491\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[16 / 30]\n",
      "Validating Now... Epoch[16 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:16\n",
      "Training Loss:0.18788757920265198 train_accuracy:0.7357512953367875\n",
      "Validation Loss:0.13821303814944655  Validation Accuracy:0.7491749174917491\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[17 / 30]\n",
      "Validating Now... Epoch[17 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:17\n",
      "Training Loss:0.2081945538520813 train_accuracy:0.7520018841262365\n",
      "Validation Loss:0.1282680546342343  Validation Accuracy:0.77007700770077\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[18 / 30]\n",
      "Validating Now... Epoch[18 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:18\n",
      "Training Loss:0.1356595754623413 train_accuracy:0.7524729156853509\n",
      "Validation Loss:0.13038936850785945  Validation Accuracy:0.757975797579758\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[19 / 30]\n",
      "Validating Now... Epoch[19 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:19\n",
      "Training Loss:0.3364247679710388 train_accuracy:0.7600094206311823\n",
      "Validation Loss:0.14026123321357994  Validation Accuracy:0.746974697469747\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[20 / 30]\n",
      "Validating Now... Epoch[20 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:20\n",
      "Training Loss:0.22842493653297424 train_accuracy:0.7710786622703721\n",
      "Validation Loss:0.13310104364281308  Validation Accuracy:0.7733773377337734\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[21 / 30]\n",
      "Validating Now... Epoch[21 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:21\n",
      "Training Loss:0.2204618602991104 train_accuracy:0.7722562411681583\n",
      "Validation Loss:0.13183602341527592  Validation Accuracy:0.7557755775577558\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[22 / 30]\n",
      "Validating Now... Epoch[22 / 30]\n",
      "Found a better loss! Epoch: 22 Validation Loss:0.12245642230717918  Validation Accuracy:0.7766776677667767\n",
      "\n",
      "Epoch Summary of Epoch:22\n",
      "Training Loss:0.22809380292892456 train_accuracy:0.7439943476212906\n",
      "Validation Loss:0.12245642230717918  Validation Accuracy:0.7766776677667767\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[23 / 30]\n",
      "Validating Now... Epoch[23 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:23\n",
      "Training Loss:1.511582851409912 train_accuracy:0.7293923692887423\n",
      "Validation Loss:0.1412290891404986  Validation Accuracy:0.7436743674367436\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[24 / 30]\n",
      "Validating Now... Epoch[24 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:24\n",
      "Training Loss:0.3887674808502197 train_accuracy:0.7404616109279322\n",
      "Validation Loss:0.16516029285584607  Validation Accuracy:0.6908690869086909\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[25 / 30]\n",
      "Validating Now... Epoch[25 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:25\n",
      "Training Loss:0.4469130337238312 train_accuracy:0.7439943476212906\n",
      "Validation Loss:0.14824531649467837  Validation Accuracy:0.6875687568756875\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[26 / 30]\n",
      "Validating Now... Epoch[26 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:26\n",
      "Training Loss:0.6421723365783691 train_accuracy:0.7428167687235044\n",
      "Validation Loss:0.12342336255036565  Validation Accuracy:0.7744774477447744\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[27 / 30]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Now... Epoch[27 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:27\n",
      "Training Loss:1.0177075862884521 train_accuracy:0.7633066415449835\n",
      "Validation Loss:0.1376195518490505  Validation Accuracy:0.7458745874587459\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[28 / 30]\n",
      "Validating Now... Epoch[28 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:28\n",
      "Training Loss:0.6480854749679565 train_accuracy:0.7687235044747998\n",
      "Validation Loss:0.12755033141053287  Validation Accuracy:0.7733773377337734\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[29 / 30]\n",
      "Validating Now... Epoch[29 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:29\n",
      "Training Loss:0.310735821723938 train_accuracy:0.7809703250117758\n",
      "Validation Loss:0.12343648180152454  Validation Accuracy:0.77007700770077\n",
      "\n",
      "Starting Next Epoch\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[30 / 30]\n",
      "Validating Now... Epoch[30 / 30]\n",
      "\n",
      "Epoch Summary of Epoch:30\n",
      "Training Loss:0.27628859877586365 train_accuracy:0.7880357983984927\n",
      "Validation Loss:0.12983666891508763  Validation Accuracy:0.7678767876787679\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "lowest_loss = sys.maxsize\n",
    "epoch_record = []\n",
    "trainLoss_record = []\n",
    "trainAccuracy_record = []\n",
    "valLoss_record = []\n",
    "valAccuracy_record=[]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStarting Next Epoch\\nLearning Rate:\",scheduler.get_lr())\n",
    "    epoch_record.append(epoch)\n",
    "    print(\"Training Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    train_loss, train_accuracy = train(resnetA,trainLoader,optimizer,criterion,one)\n",
    "    trainLoss_record.append(train_loss)\n",
    "    trainAccuracy_record.append(train_accuracy)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"Validating Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    validation_loss, validation_accuracy = evaluate(resnetA,validLoader,criterion)\n",
    "    valLoss_record.append(validation_loss)\n",
    "    valAccuracy_record.append(validation_accuracy)\n",
    "    if validation_loss<= lowest_loss:\n",
    "        lowest_loss = validation_loss\n",
    "        print(\"Found a better loss! Epoch: {} Validation Loss:{}  Validation Accuracy:{}\".format(epoch+1,validation_loss,validation_accuracy))\n",
    "        torch.save(resnetA.state_dict(),\"bestweights.pt\")\n",
    "    print(\"\\nEpoch Summary of Epoch:{}\\nTraining Loss:{} train_accuracy:{}\\nValidation Loss:{}  Validation Accuracy:{}\".format(epoch+1,train_loss,train_accuracy,validation_loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A results,without loading weights and training all layers.\n",
    "resnetA = models.resnet18(pretrained=False)\n",
    "#  Fully connected layer funnel to 2 dimension indoor and outdoor\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnetA.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetA.load_state_dict(torch.load(\"bestweights.pt\"))\n",
    "resnetA = resnet.to(device)\n",
    "test_loss, accuracy = evaluate(resnetA,testLoader,criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.13011215202379645 & Accuracy:0.7905701754385965\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:{} & Accuracy:{}\".format(test_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "plt.figure()\n",
    "plt.title(\"[A]Training Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_record, trainLoss_record)\n",
    "plt.show()\n",
    "plt.savefig('trainLoss_A.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[A]Training Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_record, trainAccuracy_record)\n",
    "plt.show()\n",
    "plt.savefig('trainAcc_A.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[A]Validation Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_record, valLoss_record)\n",
    "plt.show()\n",
    "plt.savefig('validLoss_A.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[A]Validation Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_record, valAccuracy_record)\n",
    "plt.show()\n",
    "plt.savefig('validAcc_A.png')\n",
    "\n",
    "# [A]--- Transfer learning once without loading weights and training all layers[End]---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [B] --- Transfer learning once with loading model weights before training and training all layers[Start]---\n",
    "resnetB = models.resnet18(pretrained=True) # Changed to True\n",
    "# Model resnet\n",
    "num_ftrs = resnetB.fc.in_features\n",
    "resnetB.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetB=resnetB.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batchSize = 4\n",
    "optimizer = optim.SGD(resnetB.parameters(), lr = 1e-3, momentum=0.9)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[1 / 30]\n",
      "Validating Now... Epoch[1 / 30]\n",
      "Found a better loss! Epoch: 0 Validation Loss:0.09570768812406968  Validation Accuracy:0.8283828382838284\n",
      "\n",
      "Epoch:1 \n",
      "Training Loss:0.47440242767333984 train_accuracy:0.739284032030146\n",
      "Validation Loss:0.09570768812406968 Validation Accuracy:0.8283828382838284\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[2 / 30]\n",
      "Validating Now... Epoch[2 / 30]\n",
      "\n",
      "Epoch:2 \n",
      "Training Loss:0.10020917654037476 train_accuracy:0.7468205369759774\n",
      "Validation Loss:0.12480067433861092 Validation Accuracy:0.8052805280528053\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[3 / 30]\n",
      "Validating Now... Epoch[3 / 30]\n",
      "\n",
      "Epoch:3 \n",
      "Training Loss:0.2156323790550232 train_accuracy:0.7823834196891192\n",
      "Validation Loss:0.11021320789036053 Validation Accuracy:0.8074807480748075\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[4 / 30]\n",
      "Validating Now... Epoch[4 / 30]\n",
      "Found a better loss! Epoch: 3 Validation Loss:0.09421246840615477  Validation Accuracy:0.8415841584158416\n",
      "\n",
      "Epoch:4 \n",
      "Training Loss:2.6554534435272217 train_accuracy:0.8059349976448422\n",
      "Validation Loss:0.09421246840615477 Validation Accuracy:0.8415841584158416\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[5 / 30]\n",
      "Validating Now... Epoch[5 / 30]\n",
      "\n",
      "Epoch:5 \n",
      "Training Loss:0.14909210801124573 train_accuracy:0.8167687235044748\n",
      "Validation Loss:0.10250801407005658 Validation Accuracy:0.823982398239824\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[6 / 30]\n",
      "Validating Now... Epoch[6 / 30]\n",
      "\n",
      "Epoch:6 \n",
      "Training Loss:0.1261357069015503 train_accuracy:0.8393782383419689\n",
      "Validation Loss:0.18403733637269967 Validation Accuracy:0.7029702970297029\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[7 / 30]\n",
      "Validating Now... Epoch[7 / 30]\n",
      "\n",
      "Epoch:7 \n",
      "Training Loss:0.10626935958862305 train_accuracy:0.8582195007065473\n",
      "Validation Loss:0.20426216587112814 Validation Accuracy:0.671067106710671\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[8 / 30]\n",
      "Validating Now... Epoch[8 / 30]\n",
      "Found a better loss! Epoch: 7 Validation Loss:0.09365081723996646  Validation Accuracy:0.8305830583058306\n",
      "\n",
      "Epoch:8 \n",
      "Training Loss:0.13738125562667847 train_accuracy:0.8702308054639661\n",
      "Validation Loss:0.09365081723996646 Validation Accuracy:0.8305830583058306\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[9 / 30]\n",
      "Validating Now... Epoch[9 / 30]\n",
      "Found a better loss! Epoch: 8 Validation Loss:0.08413134593151846  Validation Accuracy:0.8525852585258525\n",
      "\n",
      "Epoch:9 \n",
      "Training Loss:0.39609381556510925 train_accuracy:0.8871879415920867\n",
      "Validation Loss:0.08413134593151846 Validation Accuracy:0.8525852585258525\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[10 / 30]\n",
      "Validating Now... Epoch[10 / 30]\n",
      "\n",
      "Epoch:10 \n",
      "Training Loss:0.34910938143730164 train_accuracy:0.889543099387659\n",
      "Validation Loss:0.09675299281170396 Validation Accuracy:0.8382838283828383\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[11 / 30]\n",
      "Validating Now... Epoch[11 / 30]\n",
      "\n",
      "Epoch:11 \n",
      "Training Loss:0.19779646396636963 train_accuracy:0.8999057936881771\n",
      "Validation Loss:0.09874029659201997 Validation Accuracy:0.8393839383938394\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[12 / 30]\n",
      "Validating Now... Epoch[12 / 30]\n",
      "\n",
      "Epoch:12 \n",
      "Training Loss:0.1870872676372528 train_accuracy:0.8457371643900141\n",
      "Validation Loss:0.10776521839258825 Validation Accuracy:0.8338833883388339\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[13 / 30]\n",
      "Validating Now... Epoch[13 / 30]\n",
      "\n",
      "Epoch:13 \n",
      "Training Loss:0.47511810064315796 train_accuracy:0.8365520489872822\n",
      "Validation Loss:0.1048289205719142 Validation Accuracy:0.8426842684268426\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[14 / 30]\n",
      "Validating Now... Epoch[14 / 30]\n",
      "\n",
      "Epoch:14 \n",
      "Training Loss:0.08025228977203369 train_accuracy:0.8412623645784267\n",
      "Validation Loss:0.12298158766052249 Validation Accuracy:0.768976897689769\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[15 / 30]\n",
      "Validating Now... Epoch[15 / 30]\n",
      "\n",
      "Epoch:15 \n",
      "Training Loss:0.020466387271881104 train_accuracy:0.8593970796043335\n",
      "Validation Loss:0.10389620075524837 Validation Accuracy:0.8426842684268426\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[16 / 30]\n",
      "Validating Now... Epoch[16 / 30]\n",
      "\n",
      "Epoch:16 \n",
      "Training Loss:0.08124476671218872 train_accuracy:0.8813000471031559\n",
      "Validation Loss:0.11458886002484459 Validation Accuracy:0.856985698569857\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[17 / 30]\n",
      "Validating Now... Epoch[17 / 30]\n",
      "\n",
      "Epoch:17 \n",
      "Training Loss:0.011677563190460205 train_accuracy:0.889543099387659\n",
      "Validation Loss:0.09947556383473383 Validation Accuracy:0.8525852585258525\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[18 / 30]\n",
      "Validating Now... Epoch[18 / 30]\n",
      "\n",
      "Epoch:18 \n",
      "Training Loss:0.012081444263458252 train_accuracy:0.904851625058879\n",
      "Validation Loss:0.10428539683224738 Validation Accuracy:0.8195819581958196\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[19 / 30]\n",
      "Validating Now... Epoch[19 / 30]\n",
      "\n",
      "Epoch:19 \n",
      "Training Loss:0.10567885637283325 train_accuracy:0.9168629298162977\n",
      "Validation Loss:0.1015898640153825 Validation Accuracy:0.834983498349835\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[20 / 30]\n",
      "Validating Now... Epoch[20 / 30]\n",
      "\n",
      "Epoch:20 \n",
      "Training Loss:0.2191419154405594 train_accuracy:0.9251059821008007\n",
      "Validation Loss:0.10007037596963551 Validation Accuracy:0.8393839383938394\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[21 / 30]\n",
      "Validating Now... Epoch[21 / 30]\n",
      "\n",
      "Epoch:21 \n",
      "Training Loss:0.22855514287948608 train_accuracy:0.9265190767781442\n",
      "Validation Loss:0.10619062072176351 Validation Accuracy:0.8316831683168316\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[22 / 30]\n",
      "Validating Now... Epoch[22 / 30]\n",
      "\n",
      "Epoch:22 \n",
      "Training Loss:0.07468020915985107 train_accuracy:0.8617522373999058\n",
      "Validation Loss:0.10160114159612897 Validation Accuracy:0.8415841584158416\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[23 / 30]\n",
      "Validating Now... Epoch[23 / 30]\n",
      "\n",
      "Epoch:23 \n",
      "Training Loss:0.2518118619918823 train_accuracy:0.8617522373999058\n",
      "Validation Loss:0.10149626010912087 Validation Accuracy:0.8294829482948295\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[24 / 30]\n",
      "Validating Now... Epoch[24 / 30]\n",
      "\n",
      "Epoch:24 \n",
      "Training Loss:1.4649032354354858 train_accuracy:0.8749411210551107\n",
      "Validation Loss:0.13463972124493423 Validation Accuracy:0.7887788778877888\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[25 / 30]\n",
      "Validating Now... Epoch[25 / 30]\n",
      "\n",
      "Epoch:25 \n",
      "Training Loss:0.09186562895774841 train_accuracy:0.8944889307583608\n",
      "Validation Loss:0.12916426048322086 Validation Accuracy:0.8250825082508251\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[26 / 30]\n",
      "Validating Now... Epoch[26 / 30]\n",
      "\n",
      "Epoch:26 \n",
      "Training Loss:0.01861107349395752 train_accuracy:0.8975506358926048\n",
      "Validation Loss:0.1707021511755105 Validation Accuracy:0.7414741474147415\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[27 / 30]\n",
      "Validating Now... Epoch[27 / 30]\n",
      "\n",
      "Epoch:27 \n",
      "Training Loss:0.032302916049957275 train_accuracy:0.9163918982571833\n",
      "Validation Loss:0.1280961101352185 Validation Accuracy:0.8096809680968097\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[28 / 30]\n",
      "Validating Now... Epoch[28 / 30]\n",
      "\n",
      "Epoch:28 \n",
      "Training Loss:0.3310173451900482 train_accuracy:0.9241639189825719\n",
      "Validation Loss:0.11448655634036552 Validation Accuracy:0.847084708470847\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[29 / 30]\n",
      "Validating Now... Epoch[29 / 30]\n",
      "\n",
      "Epoch:29 \n",
      "Training Loss:0.16957873106002808 train_accuracy:0.9279321714554876\n",
      "Validation Loss:0.0992516851825158 Validation Accuracy:0.8525852585258525\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[30 / 30]\n",
      "Validating Now... Epoch[30 / 30]\n",
      "\n",
      "Epoch:30 \n",
      "Training Loss:0.058519959449768066 train_accuracy:0.9382948657560056\n",
      "Validation Loss:0.11146999388211894 Validation Accuracy:0.845984598459846\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "lowest_loss = sys.maxsize\n",
    "epoch_recordB = []\n",
    "trainLoss_recordB = []\n",
    "trainAccuracy_recordB = []\n",
    "valLoss_recordB = []\n",
    "valAccuracy_recordB=[]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Learning Rate:\",scheduler.get_lr())\n",
    "    epoch_recordB.append(epoch)\n",
    "    print(\"Training Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    train_loss, train_accuracy = train(resnetB,trainLoader,optimizer,criterion,one)\n",
    "    trainLoss_recordB.append(train_loss)\n",
    "    trainAccuracy_recordB.append(train_accuracy)\n",
    "    scheduler.step()\n",
    "    print(\"Validating Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    validation_loss, validation_accuracy = evaluate(resnetB,validLoader,criterion)\n",
    "    valLoss_recordB.append(validation_loss)\n",
    "    valAccuracy_recordB.append(validation_accuracy)\n",
    "    if validation_loss<= lowest_loss:\n",
    "        lowest_loss = validation_loss\n",
    "        print(\"Found a better loss! Epoch: {} Validation Loss:{}  Validation Accuracy:{}\".format(epoch,validation_loss,validation_accuracy))\n",
    "        torch.save(resnetB.state_dict(),\"bestweightsB.pt\")\n",
    "    print(\"\\nEpoch:{} \\nTraining Loss:{} train_accuracy:{}\\nValidation Loss:{} Validation Accuracy:{}\".format(epoch+1,train_loss,train_accuracy,validation_loss, validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B results,loading weights and training all layers.\n",
    "resnetB = models.resnet18(pretrained=True)\n",
    "# Model resnet\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnetB.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetB.load_state_dict(torch.load(\"bestweightsB.pt\"))\n",
    "resnetB = resnetB.to(device)\n",
    "test_loss, accuracy = evaluate(resnetB,testLoader,criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.09465956211645614 & Accuracy:0.8508771929824561\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:{} & Accuracy:{}\".format(test_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "plt.figure()\n",
    "plt.title(\"[B]Training Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_recordB, trainLoss_recordB)\n",
    "plt.show()\n",
    "plt.savefig('trainLoss_B.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[B]Training Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_recordB, trainAccuracy_recordB)\n",
    "plt.show()\n",
    "plt.savefig('trainAcc_B.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[B]Validation Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_recordB, valLoss_recordB)\n",
    "plt.show()\n",
    "plt.savefig('validLoss_B.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[B]Validation Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_recordB, valAccuracy_recordB)\n",
    "plt.show()\n",
    "plt.savefig('validAcc_B.png')\n",
    "\n",
    "# [B] --- Transfer learning once with loading model weights before training and training all layers[End]---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C]--- Transfer learning oonce with training only last layer, freezing the others [Start]---\n",
    "# Since Resnet has 4 layers with 1 conv layer, we dont update params for those layers\n",
    "# Only train the last one.\n",
    "resnetC = models.resnet18(pretrained=True)\n",
    "for p in resnetC.conv1.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in resnetC.layer1.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in resnetC.layer2.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in resnetC.layer3.parameters():\n",
    "    p.requires_grad = False\n",
    "#  Fully connected layer funnel to 2 dimension indoor and outdoor\n",
    "num_ftrs = resnetC.fc.in_features\n",
    "resnetC.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetC = resnetC.to(device)\n",
    "optimizer = optim.SGD(resnetC.parameters(), lr = 1e-3, momentum=0.9)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[1 / 30]\n",
      "Validating Now... Epoch[1 / 30]\n",
      "Found a better loss! Epoch: 0 Validation Loss:0.09676053775812533  Validation Accuracy:0.8415841584158416\n",
      "\n",
      "Epoch:1 \n",
      "Training Loss:0.020976543426513672 train_accuracy:0.7724917569477155\n",
      "Validation Loss:0.09676053775812533 & Accuracy:0.8415841584158416\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[2 / 30]\n",
      "Validating Now... Epoch[2 / 30]\n",
      "Found a better loss! Epoch: 1 Validation Loss:0.088835475763472  Validation Accuracy:0.8448844884488449\n",
      "\n",
      "Epoch:2 \n",
      "Training Loss:0.7729930281639099 train_accuracy:0.8007536504945831\n",
      "Validation Loss:0.088835475763472 & Accuracy:0.8448844884488449\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[3 / 30]\n",
      "Validating Now... Epoch[3 / 30]\n",
      "\n",
      "Epoch:3 \n",
      "Training Loss:0.20139656960964203 train_accuracy:0.8087611869995289\n",
      "Validation Loss:0.1444852556562004 & Accuracy:0.7458745874587459\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[4 / 30]\n",
      "Validating Now... Epoch[4 / 30]\n",
      "Found a better loss! Epoch: 3 Validation Loss:0.07681695472682663  Validation Accuracy:0.8822882288228823\n",
      "\n",
      "Epoch:4 \n",
      "Training Loss:0.027866363525390625 train_accuracy:0.8276024493641074\n",
      "Validation Loss:0.07681695472682663 & Accuracy:0.8822882288228823\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[5 / 30]\n",
      "Validating Now... Epoch[5 / 30]\n",
      "\n",
      "Epoch:5 \n",
      "Training Loss:2.8701095581054688 train_accuracy:0.8410268487988696\n",
      "Validation Loss:0.0832226999407292 & Accuracy:0.8668866886688669\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[6 / 30]\n",
      "Validating Now... Epoch[6 / 30]\n",
      "\n",
      "Epoch:6 \n",
      "Training Loss:0.10593226552009583 train_accuracy:0.8629298162976919\n",
      "Validation Loss:0.08086062277635463 & Accuracy:0.858085808580858\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[7 / 30]\n",
      "Validating Now... Epoch[7 / 30]\n",
      "\n",
      "Epoch:7 \n",
      "Training Loss:0.3123035430908203 train_accuracy:0.8768252472915685\n",
      "Validation Loss:0.08672279958808907 & Accuracy:0.847084708470847\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[8 / 30]\n",
      "Validating Now... Epoch[8 / 30]\n",
      "\n",
      "Epoch:8 \n",
      "Training Loss:0.2692100405693054 train_accuracy:0.8857748469147433\n",
      "Validation Loss:0.1537190878679781 & Accuracy:0.7557755775577558\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[9 / 30]\n",
      "Validating Now... Epoch[9 / 30]\n",
      "\n",
      "Epoch:9 \n",
      "Training Loss:2.8322830200195312 train_accuracy:0.8984926990108337\n",
      "Validation Loss:0.07769851361957714 & Accuracy:0.8844884488448845\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[10 / 30]\n",
      "Validating Now... Epoch[10 / 30]\n",
      "\n",
      "Epoch:10 \n",
      "Training Loss:0.44531768560409546 train_accuracy:0.9003768252472916\n",
      "Validation Loss:0.08913275713410446 & Accuracy:0.8448844884488449\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[11 / 30]\n",
      "Validating Now... Epoch[11 / 30]\n",
      "\n",
      "Epoch:11 \n",
      "Training Loss:0.39257460832595825 train_accuracy:0.9022609514837494\n",
      "Validation Loss:0.10511565430559079 & Accuracy:0.8272827282728272\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[12 / 30]\n",
      "Validating Now... Epoch[12 / 30]\n",
      "\n",
      "Epoch:12 \n",
      "Training Loss:1.4693330526351929 train_accuracy:0.8636363636363636\n",
      "Validation Loss:0.16792867818746893 & Accuracy:0.7348734873487349\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[13 / 30]\n",
      "Validating Now... Epoch[13 / 30]\n",
      "\n",
      "Epoch:13 \n",
      "Training Loss:0.5666603446006775 train_accuracy:0.8664625529910503\n",
      "Validation Loss:0.10783586295360517 & Accuracy:0.8283828382838284\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[14 / 30]\n",
      "Validating Now... Epoch[14 / 30]\n",
      "\n",
      "Epoch:14 \n",
      "Training Loss:0.8711333870887756 train_accuracy:0.8725859632595384\n",
      "Validation Loss:0.11399488591223267 & Accuracy:0.8811881188118812\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[15 / 30]\n",
      "Validating Now... Epoch[15 / 30]\n",
      "\n",
      "Epoch:15 \n",
      "Training Loss:1.9688444137573242 train_accuracy:0.8869524258125294\n",
      "Validation Loss:0.09699763521568479 & Accuracy:0.858085808580858\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[16 / 30]\n",
      "Validating Now... Epoch[16 / 30]\n",
      "\n",
      "Epoch:16 \n",
      "Training Loss:3.5229554176330566 train_accuracy:0.9024964672633067\n",
      "Validation Loss:0.10745843517111472 & Accuracy:0.8382838283828383\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[17 / 30]\n",
      "Validating Now... Epoch[17 / 30]\n",
      "\n",
      "Epoch:17 \n",
      "Training Loss:0.6909306049346924 train_accuracy:0.904851625058879\n",
      "Validation Loss:0.10715611481463293 & Accuracy:0.8657865786578658\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[18 / 30]\n",
      "Validating Now... Epoch[18 / 30]\n",
      "\n",
      "Epoch:18 \n",
      "Training Loss:0.11675652861595154 train_accuracy:0.9166274140367404\n",
      "Validation Loss:0.09923521420284204 & Accuracy:0.8602860286028603\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[19 / 30]\n",
      "Validating Now... Epoch[19 / 30]\n",
      "\n",
      "Epoch:19 \n",
      "Training Loss:0.15142250061035156 train_accuracy:0.9225153085256712\n",
      "Validation Loss:0.1050032512484604 & Accuracy:0.8558855885588559\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[20 / 30]\n",
      "Validating Now... Epoch[20 / 30]\n",
      "\n",
      "Epoch:20 \n",
      "Training Loss:1.330392599105835 train_accuracy:0.9218087611869995\n",
      "Validation Loss:0.08861903583157574 & Accuracy:0.8591859185918592\n",
      "Learning Rate: [2.4471741852423235e-05]\n",
      "Training Now... Epoch[21 / 30]\n",
      "Validating Now... Epoch[21 / 30]\n",
      "\n",
      "Epoch:21 \n",
      "Training Loss:0.09515437483787537 train_accuracy:0.925341497880358\n",
      "Validation Loss:0.11518074097511398 & Accuracy:0.8305830583058306\n",
      "Learning Rate: [0.001]\n",
      "Training Now... Epoch[22 / 30]\n",
      "Validating Now... Epoch[22 / 30]\n",
      "\n",
      "Epoch:22 \n",
      "Training Loss:0.04377681016921997 train_accuracy:0.8928403203014602\n",
      "Validation Loss:0.19483155895708942 & Accuracy:0.7612761276127613\n",
      "Learning Rate: [0.0009755282581475768]\n",
      "Training Now... Epoch[23 / 30]\n",
      "Validating Now... Epoch[23 / 30]\n",
      "\n",
      "Epoch:23 \n",
      "Training Loss:0.024748682975769043 train_accuracy:0.8897786151672162\n",
      "Validation Loss:0.08754242206662402 & Accuracy:0.8602860286028603\n",
      "Learning Rate: [0.0009045084971874737]\n",
      "Training Now... Epoch[24 / 30]\n",
      "Validating Now... Epoch[24 / 30]\n",
      "\n",
      "Epoch:24 \n",
      "Training Loss:0.18179851770401 train_accuracy:0.8956665096561469\n",
      "Validation Loss:0.08265012041209685 & Accuracy:0.8723872387238724\n",
      "Learning Rate: [0.0007938926261462366]\n",
      "Training Now... Epoch[25 / 30]\n",
      "Validating Now... Epoch[25 / 30]\n",
      "\n",
      "Epoch:25 \n",
      "Training Loss:3.0169215202331543 train_accuracy:0.9034385303815355\n",
      "Validation Loss:0.11208955565727714 & Accuracy:0.8657865786578658\n",
      "Learning Rate: [0.0006545084971874737]\n",
      "Training Now... Epoch[26 / 30]\n",
      "Validating Now... Epoch[26 / 30]\n",
      "\n",
      "Epoch:26 \n",
      "Training Loss:0.1401180922985077 train_accuracy:0.9128591615638247\n",
      "Validation Loss:0.13939248824572012 & Accuracy:0.8030803080308031\n",
      "Learning Rate: [0.0005]\n",
      "Training Now... Epoch[27 / 30]\n",
      "Validating Now... Epoch[27 / 30]\n",
      "\n",
      "Epoch:27 \n",
      "Training Loss:0.22761023044586182 train_accuracy:0.925341497880358\n",
      "Validation Loss:0.09686205397606945 & Accuracy:0.8525852585258525\n",
      "Learning Rate: [0.00034549150281252633]\n",
      "Training Now... Epoch[28 / 30]\n",
      "Validating Now... Epoch[28 / 30]\n",
      "\n",
      "Epoch:28 \n",
      "Training Loss:0.021835505962371826 train_accuracy:0.924399434762129\n",
      "Validation Loss:0.09875917786320444 & Accuracy:0.8679867986798679\n",
      "Learning Rate: [0.00020610737385376348]\n",
      "Training Now... Epoch[29 / 30]\n",
      "Validating Now... Epoch[29 / 30]\n",
      "\n",
      "Epoch:29 \n",
      "Training Loss:0.2425946295261383 train_accuracy:0.9331135186057465\n",
      "Validation Loss:0.1313276519820635 & Accuracy:0.8195819581958196\n",
      "Learning Rate: [9.549150281252633e-05]\n",
      "Training Now... Epoch[30 / 30]\n",
      "Validating Now... Epoch[30 / 30]\n",
      "\n",
      "Epoch:30 \n",
      "Training Loss:0.033431828022003174 train_accuracy:0.9380593499764485\n",
      "Validation Loss:0.11551071378034596 & Accuracy:0.8294829482948295\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "lowest_loss = sys.maxsize\n",
    "epoch_recordC = []\n",
    "trainLoss_recordC = []\n",
    "trainAccuracy_recordC = []\n",
    "valLoss_recordC = []\n",
    "valAccuracy_recordC=[]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Learning Rate:\",scheduler.get_lr())\n",
    "    epoch_recordC.append(epoch)\n",
    "    print(\"Training Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    train_loss, train_accuracy = train(resnetC,trainLoader,optimizer,criterion,one)\n",
    "    trainLoss_recordC.append(train_loss)\n",
    "    trainAccuracy_recordC.append(train_accuracy)\n",
    "    scheduler.step()\n",
    "    print(\"Validating Now... Epoch[{} / {}]\".format(epoch+1,epochs))\n",
    "    validation_loss, validation_accuracy = evaluate(resnetC,validLoader,criterion)\n",
    "    valLoss_recordC.append(validation_loss)\n",
    "    valAccuracy_recordC.append(validation_accuracy)\n",
    "    if validation_loss<= lowest_loss:\n",
    "        lowest_loss = validation_loss\n",
    "        print(\"Found a better loss! Epoch: {} Validation Loss:{}  Validation Accuracy:{}\".format(epoch,validation_loss,validation_accuracy))\n",
    "        torch.save(resnetC.state_dict(),\"bestweightsC.pt\")\n",
    "    print(\"\\nEpoch:{} \\nTraining Loss:{} train_accuracy:{}\\nValidation Loss:{} & Accuracy:{}\".format(epoch+1,train_loss,train_accuracy,validation_loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C results,loading weights and training all layers.\n",
    "resnetC = models.resnet18(pretrained=True)\n",
    "# Model resnet\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnetC.fc = nn.Linear(num_ftrs, 2)\n",
    "resnetC.load_state_dict(torch.load(\"bestweightsC.pt\"))\n",
    "resnetC = resnetC.to(device)\n",
    "test_loss, accuracy = evaluate(resnetC,testLoader,criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.07930669003868834 & Accuracy:0.8804824561403509\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:{} & Accuracy:{}\".format(test_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "plt.figure()\n",
    "plt.title(\"[C]Training Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_recordC, trainLoss_recordC)\n",
    "plt.show()\n",
    "plt.savefig('trainLoss_C.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[C]Training Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_recordC, trainAccuracy_recordC)\n",
    "plt.show()\n",
    "plt.savefig('trainAcc_C.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[C]Validation Loss versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epoch_recordC, valLoss_recordC)\n",
    "plt.show()\n",
    "plt.savefig('validLoss_C.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"[C]Validation Accuracy versus Epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_recordC, valAccuracy_recordC)\n",
    "plt.show()\n",
    "plt.savefig('validAcc_C.png')\n",
    "\n",
    "# [C]--- Transfer learning oonce with training only last layer, freezing the others [End]---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
